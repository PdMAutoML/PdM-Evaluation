{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7cda5781-ce99-4563-98e8-2933f8777c7f",
   "metadata": {},
   "source": [
    "## General Notes:\n",
    "\n",
    "**Online setting:** Our framework is designed to support methods suitable for online settings, specifically for streaming applications. This means that the methods can be implemented to work in real-time streaming environments or in batch processing with a streaming logic. **The key principle is that when calculating anomaly scores (or features, or any data associated with a timestamp t2), we only use data with timestamps earlier than t2.**\n",
    " For experimental purposes (and easier implementation), we use batch processing without violating the aforementioned principle.\n",
    "\n",
    "**Multimodality:** Our framework incorporates continuous and event (discrete) data. For example, it handles sensor values (continuous) and automated alarms (event data). This integration allows users to build solutions that leverage information from different types. Moreover, events are used to evaluate different solutions, such as using events that signal the start of an anomaly period or a failure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deabb4d7-200f-4a43-b04c-0fe9dfb7bc1c",
   "metadata": {},
   "source": [
    "## Implementing Semi-Supervised Method: \n",
    "\n",
    "\n",
    "In our Framework Semi-Supervised methods are used by Semi-Supervised Flavors (online,icremental and semi-supervised with historical data). All these flavors expect methods that inherit from SemiSupervisedMethodInterface class (method.semi_supervised_method.SemiSupervisedMethodInterface), which inherets from  method.method.MethodInterface (an interface where all methods should respect to be compatible with our framerwork). For easy we follow the fit-predict scheme, where fit is done in a sample of data and instantiate a model in order to be used for generating anomaly scores for new data (when predict method is called). \n",
    "\n",
    "Implementation of Semi-Supervised Model:\n",
    "* Each method should accept \"event_preferences: EventPreferences\" parameter in its constructor. This is done because in our framework we support multimodal data (both continoous and discrete). This parameter ecentially is used to provide the abillity for users to pass meta_data information in methods, for example when implementing a method and want to perform a particular action only after some events (can be ignored in other cases).\n",
    "* Methods of method.method.MethodInterface  should be implemented: There are essential for logging parameters and models (using MLflow). \n",
    "* Implementation of `fit(historic_data: list[pd.DataFrame], historic_sources: list[str], event_data: pd.DataFrame)` method: This method implements the logic of fitting or training a model to relative normal data before starting producing anomaly scores for new data. It is crucial to note that we pass multiple data from different sources (i.e. historic_data is a list of Dataframes). Someone could fit a single model for all different sources (by combining their data) or handle each source seperately.\n",
    "* Implementation of `predict(self, target_data: pd.DataFrame, source: str, event_data: pd.DataFrame)` method: This method accept a single dataframe (along with the source from which its originate) and event data. The return value must be always anomaly scores (where greater value means more anomalous data) and have the same size as the `target_data.shape[0]`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de052519-a3f1-4172-a106-43e0ce1cbf36",
   "metadata": {},
   "source": [
    "Let's implement our own Semi-Supervised method for the Framework. \n",
    "\n",
    "**Knn method**: This method calculates the anomaly score to new samples as the distance from thier k-closest neighbor in a reference data. \n",
    "* \\__init__ : Passing the parameter of k.\n",
    "* fit: stores the data to KDTree index so the calculation of nearest neighbor could be faster.\n",
    "* predict: for each sample return the distance from its k-closest neighbor in the reference set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61df6c2d-7904-4b46-be1d-ec6548122496",
   "metadata": {},
   "outputs": [],
   "source": [
    "from method.semi_supervised_method import SemiSupervisedMethodInterface \n",
    "from pdm_evaluation_types.types import EventPreferences # This is used for integrating event data, can be ignored for now\n",
    "from exceptions.exception import NotFitForSourceException # this is used in case predict method called before fit.\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import KDTree\n",
    "class my_method_knn(SemiSupervisedMethodInterface):\n",
    "    def __init__(self, event_preferences: EventPreferences,k=40, *args, **kwargs):\n",
    "        super().__init__(event_preferences=event_preferences) \n",
    "        self.k = k\n",
    "        # Use dictionaries to keep indexers of different sources\n",
    "        self.index_per_source={}\n",
    "    def fit(self, historic_data: list[pd.DataFrame], historic_sources: list[str], event_data: pd.DataFrame) -> None:\n",
    "        \"\"\"\n",
    "        Use the data of fit as reference data for each source.\n",
    "        \"\"\"\n",
    "        for df,source in zip(historic_data,historic_sources):\n",
    "            self.index_per_source[source]= KDTree(df.values, leaf_size=2) \n",
    "\n",
    "    def predict(self, target_data: pd.DataFrame, source: str, event_data: pd.DataFrame) -> list[float]:\n",
    "        if source in self.index_per_source.keys():\n",
    "            dist, ind =self.index_per_source[source].query(target_data.values, k=self.k)  \n",
    "            scores=[d[-1] for d in dist]\n",
    "            return scores\n",
    "        else:\n",
    "            raise NotFitForSourceException()\n",
    "\n",
    "    def predict_one(self, new_sample: pd.Series, source: str, is_event: bool) -> float:\n",
    "        if is_event==False:\n",
    "            if source in self.index_per_source.keys():\n",
    "                dist, ind =self.index_per_source[source].query(new_sample.values, k=self.k)  \n",
    "                return dist[-1]\n",
    "            else:\n",
    "                raise NotFitForSourceException()\n",
    "        return None\n",
    "\n",
    "    def get_library(self) -> str:\n",
    "        return 'no_save'\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return 'K nearest neighbor'\n",
    "\n",
    "    def get_params(self) -> dict:\n",
    "        return {\n",
    "            'k': self.k,\n",
    "        }\n",
    "\n",
    "    def get_all_models(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f9312d-b77b-4832-b1a1-723a4aa00e3e",
   "metadata": {},
   "source": [
    "Now run the exact code from getting started example, with our own method and parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96ea534e-6a95-4c63-81ac-505fd3d35e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -f main.o evaluator.o evaluate\n",
      "c++ -fPIC -Wall -std=c++11 -O2 -g   -c -o main.o main.cpp\n",
      "c++ -fPIC -Wall -std=c++11 -O2 -g   -c -o evaluator.o evaluator.cpp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Experiment with experiment name 'my first experiment' already exists. Be careful if you are sure about including your run in this experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c++ -fPIC -Wall -std=c++11 -O2 -g   -o evaluate main.o evaluator.o\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best score: 0.28324032008941913: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:56<00:00, 14.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'k': 1, 'profile_size': 200}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from experiment.batch.auto_profile_semi_supervised_experiment import AutoProfileSemiSupervisedPdMExperiment\n",
    "from constraint_functions.constraint import auto_profile_max_wait_time_constraint\n",
    "from pipeline.pipeline import PdMPipeline\n",
    "from utils import loadDataset\n",
    "\n",
    "dataset = loadDataset.get_dataset(\"ims\")\n",
    "\n",
    "from preprocessing.record_level.default import DefaultPreProcessor\n",
    "from postprocessing.default import DefaultPostProcessor\n",
    "from thresholding.constant import ConstantThresholder\n",
    "\n",
    "my_pipeline = PdMPipeline(\n",
    "    steps={\n",
    "        'preprocessor': DefaultPreProcessor,\n",
    "        'method': my_method_knn,\n",
    "        'postprocessor': DefaultPostProcessor,\n",
    "        'thresholder': ConstantThresholder,\n",
    "    },\n",
    "    dataset=dataset,\n",
    "    auc_resolution=100\n",
    ")\n",
    "\n",
    "param_space = {\n",
    "    'method_k': [1,2,3,5,8,10,15,20,27,40,50],\n",
    "}\n",
    "\n",
    "param_space['profile_size'] = [60, 100, 150, 200]\n",
    "\n",
    "\n",
    "my_experiment = AutoProfileSemiSupervisedPdMExperiment(\n",
    "    experiment_name='my first experiment',\n",
    "    pipeline=my_pipeline,\n",
    "    param_space=param_space,\n",
    "    num_iteration=4,\n",
    "    n_jobs=4,\n",
    "    initial_random=4,\n",
    "    constraint_function=auto_profile_max_wait_time_constraint(my_pipeline),\n",
    "    debug=True,\n",
    "    optimization_param='VUS_AUC_PR'\n",
    ")\n",
    "\n",
    "best_params = my_experiment.execute()\n",
    "print(best_params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
