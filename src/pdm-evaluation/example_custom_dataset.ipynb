{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, go through the example_run_me.ipynb notebook to get a glance of how to use pre-built datasets. For adding your own dataset, first load your dataset from its source, here we use an artificial dataset with one time-series and one feature for illustration purposes. Your dataset should have a column that determines the timestamp of each record, in case your original dataset does not have a timestamp column you can add an artificial timestamp as illustrated below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-01-01 00:01:40</td>\n",
       "      <td>0.473861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-01-02 00:01:40</td>\n",
       "      <td>1.368450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-01-03 00:01:40</td>\n",
       "      <td>-0.916827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-01-04 00:01:40</td>\n",
       "      <td>-0.124147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000-01-05 00:01:40</td>\n",
       "      <td>-2.010963</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 date   feature\n",
       "0 2000-01-01 00:01:40  0.473861\n",
       "1 2000-01-02 00:01:40  1.368450\n",
       "2 2000-01-03 00:01:40 -0.916827\n",
       "3 2000-01-04 00:01:40 -0.124147\n",
       "4 2000-01-05 00:01:40 -2.010963"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "feature = np.random.normal(loc=0, scale=1, size=10000)\n",
    "\n",
    "start_datetime = pd.Timestamp(\"2000-01-01 00:01:40\")\n",
    "datetime_column = pd.date_range(start=start_datetime, periods=feature.shape[0], freq='D')\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'date': datetime_column,\n",
    "    'feature': feature\n",
    "})\n",
    "\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After loading the time-series of your dataset you should create four lists: target_data, target_sources, historic_data and historic_sources (names do not matter here, but keys in the resulting dictionary that contains the dataset **do matter**). 'target_data' contains the time-series data we want to perform evaluation on, 'target_sources' contains an identifier for each time-series which can be artificial or real (for example the unique identifier of an asset the time-series originates from e.g. sensors of a specific vehicle), 'historic_data' contains healthy (or clean) historic data for each source that we know/assume do not contain failures and finally historic_sources contains the mapping (in 1-1 fashion) from source to healthy historic time-series. \n",
    "\n",
    "Here, we do not have any historic data available so we will create two empty lists (when no historical data is available the semisupervised with historical data flavor cannot be executed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_data = [df]\n",
    "target_sources = ['source_1']\n",
    "historic_data = []\n",
    "historic_sources = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After creating these four lists you should define where the failures occur and the failures you are interested in your evaluation. In case of run-to-failure scenarios (as in our case), meaning the failures occur at the end of each time-series, you can pass an empty dataframe for 'event_data' and empty lists for 'event_preferences'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdm_evaluation_types.types import EventPreferences, EventPreferencesTuple\n",
    "\n",
    "event_data = pd.DataFrame(columns=[\"date\", \"type\", \"source\", \"description\"])\n",
    "\n",
    "event_preferences: EventPreferences = {\n",
    "    'failure': [],\n",
    "    'reset': []\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have multiple failures per source you can create event_preferences as shown below. '*' , means that all available events will be matched and '=' means that the rules apply only for the source that the event occured in (this functionality exists because in some cases it might be beneficial to apply rules on multiple sources regardless of the source the event occured in, for example hard disk drives with different id but same manufacturer and model).\n",
    "\n",
    "For event_data the columns of the dataframe 'description', 'type' and 'source' should be str (even in case of sources that can be casted as int, for example '1') and 'date' is of type datetime as the timestamp we created for the artificial dataset on this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# event_preferences: EventPreferences = {\n",
    "#     'failure': [\n",
    "#         EventPreferencesTuple(description='*', type='fail', source='*', target_sources='=')\n",
    "#     ],\n",
    "#     'reset': [\n",
    "#         EventPreferencesTuple(description='*', type='reset', source='*', target_sources='='),\n",
    "#         EventPreferencesTuple(description='*', type='fail', source='*', target_sources='=')\n",
    "#     ]\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After defining the event related variables you can create a dictionary that will represent your dataset and use it as in the example_run_me.ipynb notebook.\n",
    "\n",
    "Information about the other keys:\n",
    "* predictive_horizon is the period we are interested in raising an alarm for an upcoming failure\n",
    "* slide is the VUS (Volume under the surface) sliding window\n",
    "* lead is the period that even if an alarm is raised an upcoming failure cannot be prevented\n",
    "* beta corresponds to the f-score computed, for example beta=1 means f1-score\n",
    "* min_historic_scenario_len is the minimum time-series length in the historic data\n",
    "* min_target_scenario_len is the minimum time-series length in the target data\n",
    "* max_wait_time is the maximum period we can tolerate not having an alarm raised\n",
    "\n",
    "All the previous values are dataset/domain dependent and usually are determined by domain experts such as engineers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import sys\n",
    "\n",
    "dataset={}\n",
    "dataset[\"dates\"]=\"date\"\n",
    "dataset[\"event_preferences\"]=event_preferences\n",
    "dataset[\"event_data\"]=event_data\n",
    "dataset[\"target_data\"]=target_data\n",
    "dataset[\"target_sources\"]=target_sources\n",
    "dataset[\"historic_data\"]=historic_data\n",
    "dataset[\"historic_sources\"]=historic_sources\n",
    "dataset[\"predictive_horizon\"]='100 days'\n",
    "dataset[\"slide\"]=50\n",
    "dataset[\"lead\"]='2 days'\n",
    "dataset[\"beta\"]=1\n",
    "dataset[\"min_historic_scenario_len\"] = sys.maxsize\n",
    "dataset[\"min_target_scenario_len\"] = min(df.shape[0] for df in target_data)\n",
    "dataset[\"max_wait_time\"] = math.ceil((1/3) * dataset[\"min_target_scenario_len\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -f main.o evaluator.o evaluate\n",
      "c++ -fPIC -Wall -std=c++11 -O2 -g   -c -o main.o main.cpp\n",
      "c++ -fPIC -Wall -std=c++11 -O2 -g   -c -o evaluator.o evaluator.cpp\n",
      "c++ -fPIC -Wall -std=c++11 -O2 -g   -o evaluate main.o evaluator.o\n",
      "{'nu': 0.05, 'kernel': 'linear', 'gamma': 'auto', 'degree': 2, 'profile_size': 150}\n",
      "{}\n",
      "{'nu': 0.01, 'kernel': 'poly', 'gamma': 'scale', 'degree': 4, 'profile_size': 200}\n",
      "{'nu': 0.1, 'kernel': 'linear', 'gamma': 'auto', 'degree': 2, 'profile_size': 150}\n",
      "{'nu': 0.05, 'kernel': 'sigmoid', 'gamma': 'scale', 'degree': 3, 'profile_size': 150}\n",
      "{}{}\n",
      "\n",
      "{}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'degree': 2, 'gamma': 'scale', 'kernel': 'poly', 'nu': 0.5, 'profile_size': 200}\n",
      "{'degree': 5, 'gamma': 'auto', 'kernel': 'rbf', 'nu': 0.05, 'profile_size': 50}\n",
      "{'degree': 2, 'gamma': 'scale', 'kernel': 'linear', 'nu': 0.5, 'profile_size': 50}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{'degree': 5, 'gamma': 'scale', 'kernel': 'rbf', 'nu': 0.15, 'profile_size': 150}\n",
      "{}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best score: 0.012224784455107704:  25%|██▌       | 1/4 [00:07<00:22,  7.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'degree': 2, 'gamma': 'auto', 'kernel': 'rbf', 'nu': 0.01, 'profile_size': 100}\n",
      "{'degree': 4, 'gamma': 'scale', 'kernel': 'sigmoid', 'nu': 0.1, 'profile_size': 150}\n",
      "{'degree': 3, 'gamma': 'scale', 'kernel': 'linear', 'nu': 0.5, 'profile_size': 150}\n",
      "{'degree': 3, 'gamma': 'auto', 'kernel': 'rbf', 'nu': 0.2, 'profile_size': 150}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best score: 0.012224784455107704:  50%|█████     | 2/4 [00:14<00:14,  7.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'degree': 4, 'gamma': 'scale', 'kernel': 'sigmoid', 'nu': 0.01, 'profile_size': 150}\n",
      "{'degree': 3, 'gamma': 'auto', 'kernel': 'sigmoid', 'nu': 0.15, 'profile_size': 50}\n",
      "{'degree': 2, 'gamma': 'scale', 'kernel': 'sigmoid', 'nu': 0.15, 'profile_size': 200}\n",
      "{'degree': 2, 'gamma': 'auto', 'kernel': 'linear', 'nu': 0.01, 'profile_size': 200}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best score: 0.012224784455107704:  75%|███████▌  | 3/4 [00:22<00:07,  7.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'degree': 5, 'gamma': 'scale', 'kernel': 'sigmoid', 'nu': 0.15, 'profile_size': 200}\n",
      "{'degree': 2, 'gamma': 'auto', 'kernel': 'rbf', 'nu': 0.1, 'profile_size': 150}\n",
      "{'degree': 3, 'gamma': 'auto', 'kernel': 'linear', 'nu': 0.5, 'profile_size': 50}\n",
      "{'degree': 5, 'gamma': 'scale', 'kernel': 'sigmoid', 'nu': 0.15, 'profile_size': 100}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best score: 0.012224784455107704: 100%|██████████| 4/4 [00:30<00:00,  7.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'profile_size': 150, 'method_nu': 0.05, 'method_kernel': 'sigmoid', 'method_gamma': 'scale', 'method_degree': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from experiment.batch.auto_profile_semi_supervised_experiment import AutoProfileSemiSupervisedPdMExperiment\n",
    "from constraint_functions.constraint import auto_profile_max_wait_time_constraint\n",
    "from pipeline.pipeline import PdMPipeline\n",
    "from method.ocsvm import OneClassSVM\n",
    "\n",
    "from preprocessing.record_level.default import DefaultPreProcessor\n",
    "from postprocessing.default import DefaultPostProcessor\n",
    "from thresholding.constant import ConstantThresholder\n",
    "\n",
    "my_pipeline = PdMPipeline(\n",
    "    steps={\n",
    "        'preprocessor': DefaultPreProcessor,\n",
    "        'method': OneClassSVM,\n",
    "        'postprocessor': DefaultPostProcessor,\n",
    "        'thresholder': ConstantThresholder,\n",
    "    },\n",
    "    dataset=dataset,\n",
    "    auc_resolution=100\n",
    ")\n",
    "\n",
    "param_space = {\n",
    "    'method_kernel': ['linear', 'rbf', 'poly', 'sigmoid'],\n",
    "    'method_nu': [0.01, 0.05, 0.1, 0.15, 0.2, 0.5],\n",
    "    'method_gamma': ['scale', 'auto'],\n",
    "    'method_degree': [2, 3, 4, 5],\n",
    "}\n",
    "\n",
    "param_space['profile_size'] = [50, 100, 150, 200]\n",
    "\n",
    "my_experiment = AutoProfileSemiSupervisedPdMExperiment(\n",
    "    experiment_name='my first experiment with a custom dataset',\n",
    "    pipeline=my_pipeline,\n",
    "    param_space=param_space,\n",
    "    num_iteration=4,\n",
    "    n_jobs=4,\n",
    "    initial_random=4,\n",
    "    constraint_function=auto_profile_max_wait_time_constraint(my_pipeline),\n",
    "    debug=True,\n",
    "    optimization_param='VUS_AUC_PR'\n",
    ")\n",
    "\n",
    "best_params = my_experiment.execute()\n",
    "print(best_params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PdM-Evaluation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
